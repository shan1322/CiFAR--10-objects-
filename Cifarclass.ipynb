{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shantanu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.python.framework import ops\n",
    "import pickle\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#from cnn_utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "        #one hot encoding in pandas best method till now\n",
    "        x=pd.Series(dict[b'labels']) \n",
    "        labels=pd.get_dummies(x)\n",
    "        labels=np.array(labels)\n",
    "    return (dict[b'data'].reshape(10000,32,32,3),labels)\n",
    "X_train,Y_train=unpickle(\"cifar-10-batches-py/data_batch_1\")\n",
    "X_test,Y_test=unpickle(\"cifar-10-batches-py/test_batch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defenition\n",
    "def place_hold(n_H0, n_W0, n_C0, n_y):#height width,depth(channel),no of Classes\n",
    "    X = tf.placeholder(tf.float32, [None, n_H0, n_W0, n_C0])\n",
    "    Y = tf.placeholder(tf.float32, [None, n_y])\n",
    "    return X,Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X,Y=place_hold(32,32,3,10)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape of input = [batch, in_height, in_width, in_channels]\n",
    " #  shape of filter = [filter_height, filter_width, in_channels, out_channels]\n",
    "def filter_weights():\n",
    "    W1 = tf.get_variable(\"W1\",[5,5,3,6],initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2 = tf.get_variable(\"W2\",[5,5,6,16],initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W3 = tf.get_variable(\"W3\",[5,5,16,128],initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2,\n",
    "                  \"W3\":W3}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    Z1 = tf.nn.conv2d(X,W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,5,5,1], strides = [1,1,1,1], padding = 'SAME')\n",
    "    Z2 = tf.nn.conv2d(P1,W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,5,5,1], strides = [1,1,1,1], padding = 'SAME')\n",
    "    Z3 = tf.nn.conv2d(P2,W3, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    P3 = tf.nn.max_pool(A3, ksize = [1,5,5,1], strides = [1,1,1,1], padding = 'SAME')\n",
    "    P3 = tf.contrib.layers.flatten(P3)\n",
    "    Z4 = tf.contrib.layers.fully_connected(P3, 10,activation_fn=None)\n",
    "    return Z4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z4, Y):\n",
    "    cost = tf.nn.softmax_cross_entropy_with_logits(logits = Z4,labels = Y)\n",
    "    cost = tf.reduce_mean(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.000001,\n",
    "          num_epochs = 100, minibatch_size =10000, print_cost = True):\n",
    "  \n",
    "    ops.reset_default_graph()                         \n",
    "    tf.set_random_seed(1)                           \n",
    "    seed = 3                                          \n",
    "    (m, n_H0, n_W0, n_C0) = 10,32,32,3        \n",
    "    n_y = Y_train.shape[1]                           \n",
    "    costs = []                                        \n",
    "    X, Y = place_hold(n_H0,n_W0,n_C0,n_y)\n",
    "    parameters =  filter_weights()\n",
    "    Z3 = forward_propagation(X,parameters)\n",
    "    cost = compute_cost(Z3,Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            minibatch_cost = 0.     \n",
    "            for i in (0,9999):\n",
    "                (minibatch_X, minibatch_Y) = X_train[i].reshape(1,32,32,3),Y_train[i].reshape(1,10)\n",
    "                _ , temp_cost = sess.run([optimizer,cost],feed_dict={X:minibatch_X,Y:minibatch_Y})\n",
    "                minibatch_cost += temp_cost   \n",
    "            print(\"epochs\"+str(epoch),minibatch_cost)\n",
    "        plt.plot(np.squeeze(minibatch_cost))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\shantanu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-8-55f38208d5b0>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "epochs0 45.446688652038574\n",
      "epochs1 34.25781726837158\n",
      "epochs2 23.50455093383789\n",
      "epochs3 14.713554680347443\n",
      "epochs4 12.727615032345057\n",
      "epochs5 11.290761485695839\n",
      "epochs6 10.097166776657104\n",
      "epochs7 9.604262351989746\n",
      "epochs8 9.200508117675781\n",
      "epochs9 8.827279806137085\n",
      "epochs10 8.467315912246704\n",
      "epochs11 8.107194423675537\n",
      "epochs12 7.734713315963745\n",
      "epochs13 7.343144655227661\n",
      "epochs14 6.936070919036865\n",
      "epochs15 6.526094675064087\n",
      "epochs16 6.127051830291748\n",
      "epochs17 5.751762866973877\n",
      "epochs18 5.414862632751465\n",
      "epochs19 5.1292887926101685\n",
      "epochs20 4.9009997844696045\n",
      "epochs21 4.716057300567627\n",
      "epochs22 4.541029095649719\n",
      "epochs23 4.3433767557144165\n",
      "epochs24 4.111666440963745\n",
      "epochs25 3.8556156158447266\n",
      "epochs26 3.590855598449707\n",
      "epochs27 3.327786922454834\n",
      "epochs28 3.0681920051574707\n",
      "epochs29 2.8102904558181763\n",
      "epochs30 2.5578701496124268\n",
      "epochs31 2.3249787092208862\n",
      "epochs32 2.1295381784439087\n",
      "epochs33 1.9732471704483032\n",
      "epochs34 1.8402532935142517\n",
      "epochs35 1.7115312814712524\n",
      "epochs36 1.58018296957016\n",
      "epochs37 1.449715793132782\n",
      "epochs38 1.325171947479248\n",
      "epochs39 1.2086930871009827\n",
      "epochs40 1.1020205616950989\n",
      "epochs41 1.0086039304733276\n",
      "epochs42 0.930378645658493\n",
      "epochs43 0.8652767539024353\n",
      "epochs44 0.8083382248878479\n",
      "epochs45 0.7558003664016724\n",
      "epochs46 0.7060830295085907\n",
      "epochs47 0.65939861536026\n",
      "epochs48 0.6161684393882751\n",
      "epochs49 0.5765094459056854\n",
      "epochs50 0.5405181050300598\n",
      "epochs51 0.5083707273006439\n",
      "epochs52 0.47995464503765106\n",
      "epochs53 0.45487214624881744\n",
      "epochs54 0.4324008524417877\n",
      "epochs55 0.4119262248277664\n",
      "epochs56 0.3928882032632828\n",
      "epochs57 0.3750886619091034\n",
      "epochs58 0.3584239035844803\n",
      "epochs59 0.34285570681095123\n",
      "epochs60 0.3283402919769287\n",
      "epochs61 0.31485916674137115\n",
      "epochs62 0.30233074724674225\n",
      "epochs63 0.29078903794288635\n",
      "epochs64 0.2801346033811569\n",
      "epochs65 0.27023111283779144\n",
      "epochs66 0.2609875276684761\n",
      "epochs67 0.252360075712204\n",
      "epochs68 0.24421147257089615\n",
      "epochs69 0.23649530112743378\n",
      "epochs70 0.22918648272752762\n",
      "epochs71 0.2222396656870842\n",
      "epochs72 0.21562548726797104\n",
      "epochs73 0.20935070514678955\n",
      "epochs74 0.20338357985019684\n",
      "epochs75 0.19772882759571075\n",
      "epochs76 0.19235003739595413\n",
      "epochs77 0.18724747002124786\n",
      "epochs78 0.18239706009626389\n",
      "epochs79 0.17776528000831604\n",
      "epochs80 0.17334215342998505\n",
      "epochs81 0.16911783814430237\n",
      "epochs82 0.16506553441286087\n",
      "epochs83 0.16118253767490387\n",
      "epochs84 0.15745484828948975\n",
      "epochs85 0.15386554598808289\n",
      "epochs86 0.15041301399469376\n",
      "epochs87 0.14707940071821213\n",
      "epochs88 0.14387164264917374\n",
      "epochs89 0.14078118652105331\n",
      "epochs90 0.13780907541513443\n",
      "epochs91 0.13494297862052917\n",
      "epochs92 0.13218529894948006\n",
      "epochs93 0.12951982021331787\n",
      "epochs94 0.1269448958337307\n",
      "epochs95 0.12445445358753204\n",
      "epochs96 0.12204461917281151\n",
      "epochs97 0.1197117455303669\n",
      "epochs98 0.11745182424783707\n",
      "epochs99 0.11526752635836601\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
