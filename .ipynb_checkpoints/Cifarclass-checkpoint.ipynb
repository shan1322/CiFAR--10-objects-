{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.python.framework import ops\n",
    "import pickle\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#from cnn_utils import *\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset ###### code https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/cifar10.py\n",
    "data_path = \"\"\n",
    "img_size = 32\n",
    "# Number of channels in each image, 3 channels: Red, Green, Blue.\n",
    "num_channels = 3\n",
    "# Length of an image when flattened to a 1-dim array.\n",
    "img_size_flat = img_size * img_size * num_channels\n",
    "# Number of classes.\n",
    "num_classes = 10\n",
    "# Number of files for the training-set.\n",
    "_num_files_train = 5\n",
    "_images_per_file = 10000\n",
    "_num_images_train = _num_files_train * _images_per_file\n",
    "def _get_file_path(filename=\"\"):\n",
    "    return os.path.join(data_path, \"cifar-10-batches-py/\", filename)\n",
    "def _unpickle(filename):\n",
    "    # Create full path for the file.\n",
    "    file_path = _get_file_path(filename)\n",
    "    print(\"Loading data: \" + file_path)\n",
    "    with open(file_path, mode='rb') as file:\n",
    "        data = pickle.load(file, encoding='bytes')\n",
    "    return data\n",
    "def _convert_images(raw):\n",
    "    # Convert the raw images from the data-files to floating-points.\n",
    "    raw_float = np.array(raw, dtype=float) / 255.0\n",
    "    # Reshape the array to 4-dimensions.\n",
    "    images = raw_float.reshape([-1, num_channels, img_size, img_size])\n",
    "    # Reorder the indices of the array.\n",
    "    images = images.transpose([0, 2, 3, 1])\n",
    "    return images\n",
    "\n",
    "\n",
    "def _load_data(filename):\n",
    "    # Load the pickled data-file.\n",
    "    data = _unpickle(filename)\n",
    "    # Get the raw images.\n",
    "    raw_images = data[b'data']\n",
    "    # Get the class-numbers for each image. Convert to numpy-array.\n",
    "    cls = np.array(data[b'labels'])\n",
    "    # Convert the images.\n",
    "    images = _convert_images(raw_images)\n",
    "    return images, cls\n",
    "def load_class_names():\n",
    "    # Load the class-names from the pickled file.\n",
    "    raw = _unpickle(filename=\"batches.meta\")[b'label_names']\n",
    "    # Convert from binary strings.\n",
    "    names = [x.decode('utf-8') for x in raw]\n",
    "    return names\n",
    "def load_training_data():\n",
    "    # Pre-allocate the arrays for the images and class-numbers for efficiency.\n",
    "    images = np.zeros(shape=[_num_images_train, img_size, img_size, num_channels], dtype=float)\n",
    "    cls = np.zeros(shape=[_num_images_train], dtype=int)\n",
    "    # Begin-index for the current batch.\n",
    "    begin = 0\n",
    "    # For each data-file.\n",
    "    for i in range(_num_files_train):\n",
    "        # Load the images and class-numbers from the data-file.\n",
    "        images_batch, cls_batch = _load_data(filename=\"data_batch_\" + str(i + 1))\n",
    "        # Number of images in this batch.\n",
    "        num_images = len(images_batch)\n",
    "        # End-index for the current batch.\n",
    "        end = begin + num_images\n",
    "        # Store the images into the array.\n",
    "        images[begin:end, :] = images_batch\n",
    "        # Store the class-numbers into the array.\n",
    "        cls[begin:end] = cls_batch\n",
    "        # The begin-index for the next batch is the current end-index.\n",
    "        begin = end\n",
    "\n",
    "    return images, cls, one_hot_encoded(class_numbers=cls, num_classes=num_classes)\n",
    "def load_test_data():\n",
    "    images, cls = _load_data(filename=\"test_batch\")\n",
    "    temp=[]\n",
    "    for i in cls:\n",
    "        temp.append(np.array(i))\n",
    "    temp1=np.array([])\n",
    "    temp1=np.insert(temp)\n",
    "    print(temp1)\n",
    "    enc = OneHotEncoder()\n",
    "    print(images, temp, enc.fit(cls))\n",
    "    return images, temp, enc.fit(cls)\n",
    "\n",
    "\n",
    "load_test_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocess\n",
    "def preprocess(data):\n",
    "    img = image.load_img(data, target_size=(227,227,2))\n",
    "    x = image.img_to_array(img)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defenition\n",
    "def place_hold(n_H0, n_W0, n_C0, n_y):\n",
    "    X=tf.placeholder(tf.float32,[None,n_H0,n_C0,n_y])\n",
    "    Y=tf.placeholder(tf.float32,[None,n_y])\n",
    "    return X,Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 227, 2, 2), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X,Y=place_hold(227,227,2,2)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_weights():\n",
    "    W1=tf.get_variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
